{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu4JWRL3zUHf"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade small-text[transformers]==1.0.0b3\n",
        "! pip install scikit-multilearn\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from small_text.integrations.transformers.datasets import TransformersDataset\n",
        "from small_text.active_learner import PoolBasedActiveLearner\n",
        "from small_text.initialization import random_initialization_balanced, random_initialization, random_initialization_stratified\n",
        "from small_text.integrations.transformers import TransformerModelArguments\n",
        "from small_text.integrations.transformers.classifiers.factories import TransformerBasedClassificationFactory\n",
        "from small_text.query_strategies import PredictionEntropy, RandomSampling, ContrastiveActiveLearning\n",
        "from small_text.integrations.transformers import TransformerModelArguments\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from skmultilearn.model_selection import IterativeStratification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get GPU info\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "3PCMIgSxy_hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to drive, read dataset csv for the Cycling Dialogues from \"./drive/My Drive/EGOV-2022/dataset.csv\" and transform the dataset."
      ],
      "metadata": {
        "id": "ffE5Crqi-ntY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87q0JphAnfpA",
        "outputId": "d5d99eed-8fc2-4cae-a766-80efeb227359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_raddialoge = pd.read_csv(\"raddialog-thematic-eng.csv\")\n",
        "df_raddialoge = pd.read_csv(\"./drive/My Drive/EGOV-2022/dataset.csv\")\n",
        "\n",
        "# combine title and text as one column\n",
        "df_raddialoge.fillna('', inplace=True)\n",
        "df_raddialoge['title_text'] = df_raddialoge['title'] + \" \" + df_raddialoge['text']\n",
        "\n",
        "# get separated dataframes for each city\n",
        "df_b = df_raddialoge[df_raddialoge['dataset'] == 'B']\n",
        "df_e = df_raddialoge[df_raddialoge['dataset'] == 'E']\n",
        "df_m = df_raddialoge[df_raddialoge['dataset'] == 'M']\n",
        "\n",
        "X_b, X_e, X_m = df_b['title_text'].tolist(), df_e['title_text'].tolist(), df_m['title_text'].tolist()\n",
        "\n",
        "'''\n",
        "single label preparation\n",
        "'''\n",
        "le = LabelEncoder()\n",
        "y_b, y_e, y_m = le.fit_transform(df_b['main_category_level1']), le.fit_transform(df_e['main_category_level1']), le.fit_transform(df_m['main_category_level1'])\n",
        "\n",
        "num_classes = np.unique(y_b).shape[0]\n",
        "\n",
        "'''\n",
        "multi label preparation\n",
        "'''\n",
        "multi_cols = ['level1_traffic_lights', 'level1_lighting', 'level1_signage', 'level1_bicycle_parking',\n",
        "                           'level1_obstacles', 'level1_cycling_traffic_management', 'level1_cycle_path_quality',\n",
        "                           'level1_misc']\n",
        "\n",
        "y_b_multi, y_e_multi, y_m_multi = df_b[multi_cols].to_numpy(), df_e[multi_cols].to_numpy(), df_m[multi_cols].to_numpy()"
      ],
      "metadata": {
        "id": "Qer1JfpC-3dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation for BERT"
      ],
      "metadata": {
        "id": "v99KG8uf1GoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model_name = 'deepset/gbert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(transformer_model_name, do_lower_case=False)"
      ],
      "metadata": {
        "id": "EsxkJKfd0_a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transformers_dataset(tokenizer, data, labels, max_length=256, multi_label=False):\n",
        "\n",
        "    data_out = []\n",
        "\n",
        "    for i, doc in enumerate(data):\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            doc,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation='longest_first'\n",
        "        )\n",
        "\n",
        "        #data_out.append((encoded_dict['input_ids'], encoded_dict['attention_mask'], labels[i]))\n",
        "\n",
        "        if multi_label:\n",
        "            data_out.append((encoded_dict['input_ids'],\n",
        "                             encoded_dict['attention_mask'],\n",
        "                             labels[i]))#sparse.csr_matrix(labels[i]))) #np.sort(labels[i]))\n",
        "                             #torch.tensor([labels[i]], dtype=torch.float)))\n",
        "        else:\n",
        "            data_out.append((encoded_dict['input_ids'],\n",
        "                             encoded_dict['attention_mask'],\n",
        "                             labels[i]))\n",
        "\n",
        "    return TransformersDataset(data_out, multi_label=multi_label) #, target_labels=[0,1,2,3,4,5,6,7])"
      ],
      "metadata": {
        "id": "CRgC38zb1Prd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Active Learner"
      ],
      "metadata": {
        "id": "EGqRwwfn1Tds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simulates an initial labeling to warm-start the active learning process\n",
        "def initialize_active_learner(active_learner, y_train, x_train):\n",
        "\n",
        "    #indices_initial = random_initialization_balanced(y_train, n_samples=20)\n",
        "    indices_initial = random_initialization(x_train, n_samples=20)\n",
        "    active_learner.initialize_data(indices_initial, y_train[indices_initial])\n",
        "\n",
        "    return indices_initial"
      ],
      "metadata": {
        "id": "Dhg4U408koJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Active Learning Loop"
      ],
      "metadata": {
        "id": "gc6f_KfV1frV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(active_learner, train, test):\n",
        "    y_pred_train = active_learner.classifier.predict(train)\n",
        "    y_pred_test = active_learner.classifier.predict(test)\n",
        "\n",
        "    test_acc = f1_score(test.y, y_pred_test, average='micro')\n",
        "\n",
        "    print('Train accuracy: {:.2f}'.format(f1_score(train.y, y_pred_train, average='micro')))\n",
        "    print('Test accuracy: {:.2f}'.format(test_acc))\n",
        "\n",
        "    print(classification_report(test.y, y_pred_test))\n",
        "    \n",
        "    return test_acc"
      ],
      "metadata": {
        "id": "QJsRle6VC3gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run 5-fold CV\n",
        "def AlCV(X_in, y_in, d, qs, bs, non_active, multi, split_start):\n",
        "\n",
        "    X = X_in\n",
        "    y = y_in\n",
        "\n",
        "    if multi:\n",
        "        skf = IterativeStratification(n_splits=5, order=1)\n",
        "    else:\n",
        "        skf = StratifiedKFold(n_splits=5)\n",
        "        skf.get_n_splits(X, y)\n",
        "\n",
        "    split = 1\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "\n",
        "      print(\"Split\",split)\n",
        "\n",
        "      if split >= split_start:\n",
        "\n",
        "          # prepare dataset\n",
        "          X_train, X_test = [X_in[index] for index in train_index], [X_in[index] for index in test_index]\n",
        "          y_train, y_test = y_in[train_index], y_in[test_index]\n",
        "\n",
        "          train = get_transformers_dataset(tokenizer, X_train, y_train)#, multi_label=multi)\n",
        "          test = get_transformers_dataset(tokenizer, X_test, y_test)#, multi_label=multi)\n",
        "\n",
        "          # init the model and query strategy\n",
        "          transformer_model = TransformerModelArguments(transformer_model_name)\n",
        "          clf_factory = TransformerBasedClassificationFactory(transformer_model, \n",
        "                                                              num_classes=num_classes, \n",
        "                                                              kwargs=dict({'device': 'cuda', \n",
        "                                                                          'mini_batch_size': bs,\n",
        "                                                                          'class_weight': 'balanced', # for single label\n",
        "                                                                          #'multi_label': multi\n",
        "                                                                          }))\n",
        "              \n",
        "          query_strategy = qs\n",
        "\n",
        "          active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, train, reuse_model=True)\n",
        "          indices_labeled = initialize_active_learner(active_learner, train.y, train.x)\n",
        "\n",
        "          # active learning loop\n",
        "\n",
        "          num_samples = 20\n",
        "          tmp = (len(X_train)-num_samples)/num_samples\n",
        "          if tmp > int(tmp):\n",
        "            num_queries = min(int(tmp) + 1, 30)\n",
        "          else:\n",
        "            num_queries = min(int(tmp), 30)\n",
        "\n",
        "          if non_active:\n",
        "              num_queries = 1\n",
        "              \n",
        "          # time stamps\n",
        "          query_times = []\n",
        "          user_simulation_times = []\n",
        "          update_times = []\n",
        "          evaluation_times = []\n",
        "          overall_iteration_times = []\n",
        "\n",
        "          # get results per iteration\n",
        "          results = []\n",
        "          results.append(evaluate(active_learner, train[indices_labeled], test))\n",
        "\n",
        "          # get labels per iteration\n",
        "          labels_in_pool = []\n",
        "          labels_in_pool.append(train.y[indices_labeled])\n",
        "\n",
        "          for i in range(num_queries):\n",
        "\n",
        "              start_time = time.time()\n",
        "\n",
        "              # ...where each iteration consists of labelling 20 samples\n",
        "              if i == num_queries-1:\n",
        "                  num_samples = len(X_train) - (num_queries*num_samples)\n",
        "\n",
        "              indices_queried = active_learner.query(num_samples=num_samples)\n",
        "\n",
        "              query_time = time.time()\n",
        "              query_times.append(query_time - start_time)\n",
        "\n",
        "              # Simulate user interaction here. Replace this for real-world usage.\n",
        "              y = train.y[indices_queried]\n",
        "\n",
        "              user_simulation_time = time.time()\n",
        "              user_simulation_times.append(user_simulation_time - query_time)\n",
        "\n",
        "              # Return the labels for the current query to the active learner.\n",
        "              active_learner.update(y)\n",
        "\n",
        "              indices_labeled = np.concatenate([indices_queried, indices_labeled])\n",
        "\n",
        "              update_time = time.time()\n",
        "              update_times.append(update_time - user_simulation_time)\n",
        "                  \n",
        "              print('---------------')\n",
        "              print(f'Iteration #{i} ({len(indices_labeled)} samples)')\n",
        "              results.append(evaluate(active_learner, train[indices_labeled], test))\n",
        "\n",
        "              labels_in_pool.append(train.y[indices_labeled])\n",
        "\n",
        "              evaluation_time = time.time()\n",
        "              evaluation_times.append(evaluation_time - update_time)\n",
        "\n",
        "              overall_iteration_times.append(evaluation_time - start_time)\n",
        "\n",
        "          summary = {\n",
        "                  'results': results,\n",
        "                  'query_times': query_times,\n",
        "                  'user_simulation_times':  user_simulation_times,\n",
        "                  'update_times': update_times,\n",
        "                  'evaluation_times': evaluation_times,\n",
        "                  'overall_iteration_times': overall_iteration_times,\n",
        "                  'labels_in_pool': labels_in_pool\n",
        "                  }\n",
        "\n",
        "          print(summary)\n",
        "\n",
        "      split += 1"
      ],
      "metadata": {
        "id": "bnhnLU-_j0oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example usage for an Active Learning experiment:\n",
        "ALCV(X_dataset, y_dataset, dataset_code, query_strategy, batch_size, non_active, multi, split_start):\n",
        "\n",
        "\n",
        "*   non_active: if True perform full supervision experiment, else if False perform Active Learning experiment.\n",
        "*   multi: if True perform multi-class prediction, else if False perform single-class prediction.\n",
        "*   split_start: if 1 then all five cross validation splits are used. \n",
        "\n"
      ],
      "metadata": {
        "id": "WHJEtsLCpNZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AlCV(X_b, y_b, \"B\", RandomSampling(), 2, non_active=False, multi=False, split_start=1)"
      ],
      "metadata": {
        "id": "kTWLWA81YGIY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}